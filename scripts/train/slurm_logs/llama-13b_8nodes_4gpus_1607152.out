+ module purge
+ local _mlredir=1
+ '[' -n '' ']'
+ case " $@ " in
+ '[' 1 -eq 0 ']'
+ _module_raw purge
++ /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/tcl-8.6.12-rdtv2pt4tnckxsgwtowik3sbexmxolve/bin/tclsh /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/libexec/modulecmd.tcl bash purge
Unloading profile/base
  ERROR: Module evaluation aborted
+ eval 'unset CPATH;
unset CMAKE_PREFIX_PATH;
unset CINECA_AI_LIB;
unset __MODULES_LMTAG;
unset OPENMPI_INC;
unset C_INCLUDE_PATH;
unset F77;
unset OPENMPI_LIB;
unset GCC_INCLUDE;
unset CUDA_INCLUDE;
MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man; export MANPATH;
unset MPC_INC;
unset ZLIB_HOME;
unset MPIF77;
unset PKG_CONFIG_PATH;
unset OMPI_MCA_coll_hcoll_enable;
unset __MODULES_LMPREREQ;
unset CUDA_INC;
unset GCC_INC;
unset MPC_LIB;
unset CINECA_AI_INCLUDE;
unset F90;
unset MPFR_INCLUDE;
__MODULES_LMALTNAME=profile/base\&profile/default\&profile; export __MODULES_LMALTNAME;
MODULEPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/modulefiles:/leonardo/prod/opt/modulefiles/profiles:/leonardo/prod/opt/modulefiles/base/archive:/leonardo/prod/opt/modulefiles/base/dependencies:/leonardo/prod/opt/modulefiles/base/data:/leonardo/prod/opt/modulefiles/base/environment:/leonardo/prod/opt/modulefiles/base/libraries:/leonardo/prod/opt/modulefiles/base/tools:/leonardo/prod/opt/modulefiles/base/compilers:/leonardo/prod/opt/modulefiles/base/applications; export MODULEPATH;
unset CUDA_LIB;
unset GCC_LIB;
unset GMP_HOME;
unset GMP_INC;
PATH=/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin; export PATH;
unset MPIF90;
unset CUDA_HOME;
unset GCC_HOME;
unset MPFR_INC;
unset CC;
unset LD_LIBRARY_PATH;
unset GMP_LIB;
LOADEDMODULES=profile/base; export LOADEDMODULES;
unset MPFR_LIB;
unset OPENMPI_INCLUDE;
unset CXX;
unset ZLIB_INCLUDE;
unset MPFR_HOME;
unset OPENMPI_HOME;
unset MPICXX;
unset ZLIB_INC;
unset MPC_INCLUDE;
unset ZLIB_LIB;
unset MPC_HOME;
unset LIBRARY_PATH;
_LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base; export _LMFILES_;
unset MPICC;
unset CPLUS_INCLUDE_PATH;
unset GMP_INCLUDE;
unset FC;
unset __MODULES_LMCONFLICT;
unset CINECA_AI_HOME;
unset CINECA_AI_INC;
test 0 = 1;'
++ unset CPATH
++ unset CMAKE_PREFIX_PATH
++ unset CINECA_AI_LIB
++ unset __MODULES_LMTAG
++ unset OPENMPI_INC
++ unset C_INCLUDE_PATH
++ unset F77
++ unset OPENMPI_LIB
++ unset GCC_INCLUDE
++ unset CUDA_INCLUDE
++ MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man
++ export MANPATH
++ unset MPC_INC
++ unset ZLIB_HOME
++ unset MPIF77
++ unset PKG_CONFIG_PATH
++ unset OMPI_MCA_coll_hcoll_enable
++ unset __MODULES_LMPREREQ
++ unset CUDA_INC
++ unset GCC_INC
++ unset MPC_LIB
++ unset CINECA_AI_INCLUDE
++ unset F90
++ unset MPFR_INCLUDE
++ __MODULES_LMALTNAME='profile/base&profile/default&profile'
++ export __MODULES_LMALTNAME
++ MODULEPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/modulefiles:/leonardo/prod/opt/modulefiles/profiles:/leonardo/prod/opt/modulefiles/base/archive:/leonardo/prod/opt/modulefiles/base/dependencies:/leonardo/prod/opt/modulefiles/base/data:/leonardo/prod/opt/modulefiles/base/environment:/leonardo/prod/opt/modulefiles/base/libraries:/leonardo/prod/opt/modulefiles/base/tools:/leonardo/prod/opt/modulefiles/base/compilers:/leonardo/prod/opt/modulefiles/base/applications
++ export MODULEPATH
++ unset CUDA_LIB
++ unset GCC_LIB
++ unset GMP_HOME
++ unset GMP_INC
++ PATH=/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ unset MPIF90
++ unset CUDA_HOME
++ unset GCC_HOME
++ unset MPFR_INC
++ unset CC
++ unset LD_LIBRARY_PATH
++ unset GMP_LIB
++ LOADEDMODULES=profile/base
++ export LOADEDMODULES
++ unset MPFR_LIB
++ unset OPENMPI_INCLUDE
++ unset CXX
++ unset ZLIB_INCLUDE
++ unset MPFR_HOME
++ unset OPENMPI_HOME
++ unset MPICXX
++ unset ZLIB_INC
++ unset MPC_INCLUDE
++ unset ZLIB_LIB
++ unset MPC_HOME
++ unset LIBRARY_PATH
++ _LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base
++ export _LMFILES_
++ unset MPICC
++ unset CPLUS_INCLUDE_PATH
++ unset GMP_INCLUDE
++ unset FC
++ unset __MODULES_LMCONFLICT
++ unset CINECA_AI_HOME
++ unset CINECA_AI_INC
++ test 0 = 1
+ _mlstatus=1
+ return 1
+ module load gcc
+ local _mlredir=1
+ '[' -n '' ']'
+ case " $@ " in
+ '[' 1 -eq 0 ']'
+ _module_raw load gcc
++ /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/tcl-8.6.12-rdtv2pt4tnckxsgwtowik3sbexmxolve/bin/tclsh /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/libexec/modulecmd.tcl bash load gcc
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
+ eval 'GCC_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include; export GCC_INCLUDE;
MPC_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb; export MPC_HOME;
LD_LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LD_LIBRARY_PATH;
CPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPATH;
MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man; export MANPATH;
MPC_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include; export MPC_INC;
LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LIBRARY_PATH;
_LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0; export _LMFILES_;
GMP_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export GMP_LIB;
CMAKE_PREFIX_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.; export CMAKE_PREFIX_PATH;
LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0; export LOADEDMODULES;
CXX=g++; export CXX;
MPFR_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib; export MPFR_LIB;
__MODULES_LMTAG=gmp/6.2.1\&auto-loaded:mpfr/4.1.0\&auto-loaded:mpc/1.2.1\&auto-loaded; export __MODULES_LMTAG;
PKG_CONFIG_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig; export PKG_CONFIG_PATH;
MPFR_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc; export MPFR_HOME;
GCC_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include; export GCC_INC;
MPC_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib; export MPC_LIB;
__MODULES_LMPREREQ=mpfr/4.1.0\&gmp/6.2.1:mpc/1.2.1\&gmp/6.2.1\&mpfr/4.1.0:gcc/11.3.0\&gmp/6.2.1\&mpc/1.2.1\&mpfr/4.1.0; export __MODULES_LMPREREQ;
CPLUS_INCLUDE_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPLUS_INCLUDE_PATH;
F90=gfortran; export F90;
GMP_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export GMP_INCLUDE;
MPFR_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include; export MPFR_INCLUDE;
FC=gfortran; export FC;
__MODULES_LMALTNAME=profile/base\&profile/default\&profile:gmp/6.2.1\&as\|gmp/default\&as\|gmp/latest:mpfr/4.1.0\&as\|mpfr/default\&as\|mpfr/latest:mpc/1.2.1\&as\|mpc/default\&as\|mpc/latest:gcc/11.3.0\&as\|gcc/default\&as\|gcc/latest; export __MODULES_LMALTNAME;
__MODULES_LMCONFLICT=gmp/6.2.1\&gmp:mpfr/4.1.0\&mpfr:mpc/1.2.1\&mpc:gcc/11.3.0\&gcc; export __MODULES_LMCONFLICT;
C_INCLUDE_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export C_INCLUDE_PATH;
GCC_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib; export GCC_LIB;
MPC_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include; export MPC_INCLUDE;
F77=gfortran; export F77;
GMP_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22; export GMP_HOME;
GCC_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza; export GCC_HOME;
PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin; export PATH;
GMP_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export GMP_INC;
CC=gcc; export CC;
MPFR_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include; export MPFR_INC;
test 0;'
++ GCC_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include
++ export GCC_INCLUDE
++ MPC_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb
++ export MPC_HOME
++ LD_LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LD_LIBRARY_PATH
++ CPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPATH
++ MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man
++ export MANPATH
++ MPC_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include
++ export MPC_INC
++ LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LIBRARY_PATH
++ _LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0
++ export _LMFILES_
++ GMP_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export GMP_LIB
++ CMAKE_PREFIX_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.
++ export CMAKE_PREFIX_PATH
++ LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0
++ export LOADEDMODULES
++ CXX=g++
++ export CXX
++ MPFR_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib
++ export MPFR_LIB
++ __MODULES_LMTAG='gmp/6.2.1&auto-loaded:mpfr/4.1.0&auto-loaded:mpc/1.2.1&auto-loaded'
++ export __MODULES_LMTAG
++ PKG_CONFIG_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig
++ export PKG_CONFIG_PATH
++ MPFR_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc
++ export MPFR_HOME
++ GCC_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include
++ export GCC_INC
++ MPC_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib
++ export MPC_LIB
++ __MODULES_LMPREREQ='mpfr/4.1.0&gmp/6.2.1:mpc/1.2.1&gmp/6.2.1&mpfr/4.1.0:gcc/11.3.0&gmp/6.2.1&mpc/1.2.1&mpfr/4.1.0'
++ export __MODULES_LMPREREQ
++ CPLUS_INCLUDE_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPLUS_INCLUDE_PATH
++ F90=gfortran
++ export F90
++ GMP_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export GMP_INCLUDE
++ MPFR_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include
++ export MPFR_INCLUDE
++ FC=gfortran
++ export FC
++ __MODULES_LMALTNAME='profile/base&profile/default&profile:gmp/6.2.1&as|gmp/default&as|gmp/latest:mpfr/4.1.0&as|mpfr/default&as|mpfr/latest:mpc/1.2.1&as|mpc/default&as|mpc/latest:gcc/11.3.0&as|gcc/default&as|gcc/latest'
++ export __MODULES_LMALTNAME
++ __MODULES_LMCONFLICT='gmp/6.2.1&gmp:mpfr/4.1.0&mpfr:mpc/1.2.1&mpc:gcc/11.3.0&gcc'
++ export __MODULES_LMCONFLICT
++ C_INCLUDE_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export C_INCLUDE_PATH
++ GCC_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib
++ export GCC_LIB
++ MPC_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include
++ export MPC_INCLUDE
++ F77=gfortran
++ export F77
++ GMP_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22
++ export GMP_HOME
++ GCC_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza
++ export GCC_HOME
++ PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ GMP_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export GMP_INC
++ CC=gcc
++ export CC
++ MPFR_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include
++ export MPFR_INC
++ test 0
+ _mlstatus=0
+ return 0
+ module load cuda
+ local _mlredir=1
+ '[' -n '' ']'
+ case " $@ " in
+ '[' 1 -eq 0 ']'
+ _module_raw load cuda
++ /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/tcl-8.6.12-rdtv2pt4tnckxsgwtowik3sbexmxolve/bin/tclsh /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/libexec/modulecmd.tcl bash load cuda
+ eval 'LD_LIBRARY_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/compat:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LD_LIBRARY_PATH;
CUDA_INCLUDE=/leonardo/prod/opt/compilers/cuda/11.8/none/include; export CUDA_INCLUDE;
CPATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPATH;
LIBRARY_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LIBRARY_PATH;
MANPATH=/leonardo/prod/opt/compilers/cuda/11.8/none/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man; export MANPATH;
_LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8; export _LMFILES_;
LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8; export LOADEDMODULES;
CMAKE_PREFIX_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.; export CMAKE_PREFIX_PATH;
PKG_CONFIG_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig; export PKG_CONFIG_PATH;
CUDA_INC=/leonardo/prod/opt/compilers/cuda/11.8/none/include; export CUDA_INC;
CPLUS_INCLUDE_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPLUS_INCLUDE_PATH;
__MODULES_LMALTNAME=profile/base\&profile/default\&profile:gmp/6.2.1\&as\|gmp/default\&as\|gmp/latest:mpfr/4.1.0\&as\|mpfr/default\&as\|mpfr/latest:mpc/1.2.1\&as\|mpc/default\&as\|mpc/latest:gcc/11.3.0\&as\|gcc/default\&as\|gcc/latest:cuda/11.8\&as\|cuda/default\&as\|cuda/latest; export __MODULES_LMALTNAME;
__MODULES_LMCONFLICT=gmp/6.2.1\&gmp:mpfr/4.1.0\&mpfr:mpc/1.2.1\&mpc:gcc/11.3.0\&gcc:cuda/11.8\&cuda; export __MODULES_LMCONFLICT;
C_INCLUDE_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export C_INCLUDE_PATH;
CUDA_LIB=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64; export CUDA_LIB;
CUDA_HOME=/leonardo/prod/opt/compilers/cuda/11.8/none; export CUDA_HOME;
PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/samples/bin/x86_64/linux/release/:/leonardo/prod/opt/compilers/cuda/11.8/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin; export PATH;
test 0;'
++ LD_LIBRARY_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/compat:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LD_LIBRARY_PATH
++ CUDA_INCLUDE=/leonardo/prod/opt/compilers/cuda/11.8/none/include
++ export CUDA_INCLUDE
++ CPATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPATH
++ LIBRARY_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LIBRARY_PATH
++ MANPATH=/leonardo/prod/opt/compilers/cuda/11.8/none/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man
++ export MANPATH
++ _LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8
++ export _LMFILES_
++ LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8
++ export LOADEDMODULES
++ CMAKE_PREFIX_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.
++ export CMAKE_PREFIX_PATH
++ PKG_CONFIG_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig
++ export PKG_CONFIG_PATH
++ CUDA_INC=/leonardo/prod/opt/compilers/cuda/11.8/none/include
++ export CUDA_INC
++ CPLUS_INCLUDE_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPLUS_INCLUDE_PATH
++ __MODULES_LMALTNAME='profile/base&profile/default&profile:gmp/6.2.1&as|gmp/default&as|gmp/latest:mpfr/4.1.0&as|mpfr/default&as|mpfr/latest:mpc/1.2.1&as|mpc/default&as|mpc/latest:gcc/11.3.0&as|gcc/default&as|gcc/latest:cuda/11.8&as|cuda/default&as|cuda/latest'
++ export __MODULES_LMALTNAME
++ __MODULES_LMCONFLICT='gmp/6.2.1&gmp:mpfr/4.1.0&mpfr:mpc/1.2.1&mpc:gcc/11.3.0&gcc:cuda/11.8&cuda'
++ export __MODULES_LMCONFLICT
++ C_INCLUDE_PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export C_INCLUDE_PATH
++ CUDA_LIB=/leonardo/prod/opt/compilers/cuda/11.8/none/lib64
++ export CUDA_LIB
++ CUDA_HOME=/leonardo/prod/opt/compilers/cuda/11.8/none
++ export CUDA_HOME
++ PATH=/leonardo/prod/opt/compilers/cuda/11.8/none/samples/bin/x86_64/linux/release/:/leonardo/prod/opt/compilers/cuda/11.8/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ test 0
+ _mlstatus=0
+ return 0
+ module load profile/deeplrn
+ local _mlredir=1
+ '[' -n '' ']'
+ case " $@ " in
+ '[' 1 -eq 0 ']'
+ _module_raw load profile/deeplrn
++ /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/tcl-8.6.12-rdtv2pt4tnckxsgwtowik3sbexmxolve/bin/tclsh /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/libexec/modulecmd.tcl bash load profile/deeplrn
+ eval '_LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8:/leonardo/prod/opt/modulefiles/profiles/profile/deeplrn; export _LMFILES_;
LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8:profile/deeplrn; export LOADEDMODULES;
MODULEPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/modulefiles:/leonardo/prod/opt/modulefiles/profiles:/leonardo/prod/opt/modulefiles/base/archive:/leonardo/prod/opt/modulefiles/base/dependencies:/leonardo/prod/opt/modulefiles/base/data:/leonardo/prod/opt/modulefiles/base/environment:/leonardo/prod/opt/modulefiles/base/libraries:/leonardo/prod/opt/modulefiles/base/tools:/leonardo/prod/opt/modulefiles/base/compilers:/leonardo/prod/opt/modulefiles/base/applications:/leonardo/prod/opt/modulefiles/deeplrn/archive:/leonardo/prod/opt/modulefiles/deeplrn/dependencies:/leonardo/prod/opt/modulefiles/deeplrn/data:/leonardo/prod/opt/modulefiles/deeplrn/environment:/leonardo/prod/opt/modulefiles/deeplrn/libraries:/leonardo/prod/opt/modulefiles/deeplrn/tools:/leonardo/prod/opt/modulefiles/deeplrn/compilers:/leonardo/prod/opt/modulefiles/deeplrn/applications; export MODULEPATH;
test 0;'
++ _LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8:/leonardo/prod/opt/modulefiles/profiles/profile/deeplrn
++ export _LMFILES_
++ LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8:profile/deeplrn
++ export LOADEDMODULES
++ MODULEPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/modulefiles:/leonardo/prod/opt/modulefiles/profiles:/leonardo/prod/opt/modulefiles/base/archive:/leonardo/prod/opt/modulefiles/base/dependencies:/leonardo/prod/opt/modulefiles/base/data:/leonardo/prod/opt/modulefiles/base/environment:/leonardo/prod/opt/modulefiles/base/libraries:/leonardo/prod/opt/modulefiles/base/tools:/leonardo/prod/opt/modulefiles/base/compilers:/leonardo/prod/opt/modulefiles/base/applications:/leonardo/prod/opt/modulefiles/deeplrn/archive:/leonardo/prod/opt/modulefiles/deeplrn/dependencies:/leonardo/prod/opt/modulefiles/deeplrn/data:/leonardo/prod/opt/modulefiles/deeplrn/environment:/leonardo/prod/opt/modulefiles/deeplrn/libraries:/leonardo/prod/opt/modulefiles/deeplrn/tools:/leonardo/prod/opt/modulefiles/deeplrn/compilers:/leonardo/prod/opt/modulefiles/deeplrn/applications
++ export MODULEPATH
++ test 0
+ _mlstatus=0
+ return 0
+ module load cineca-ai
+ local _mlredir=1
+ '[' -n '' ']'
+ case " $@ " in
+ '[' 1 -eq 0 ']'
+ _module_raw load cineca-ai
++ /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/tcl-8.6.12-rdtv2pt4tnckxsgwtowik3sbexmxolve/bin/tclsh /leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/libexec/modulecmd.tcl bash load cineca-ai
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
+ eval 'LD_LIBRARY_PATH=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/lib:/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/lib64:/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib:/leonardo/prod/opt/compilers/cuda/11.8/none/compat:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LD_LIBRARY_PATH;
CPATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/python-3.10.8-eauysn2mronkqqffs7r6bvftsdpsfm4b/include/python3.10:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPATH;
LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib; export LIBRARY_PATH;
MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man; export MANPATH;
ZLIB_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk; export ZLIB_HOME;
CINECA_AI_LIB=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/lib; export CINECA_AI_LIB;
MPIF77=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpif77; export MPIF77;
_LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8:/leonardo/prod/opt/modulefiles/profiles/profile/deeplrn:/leonardo/prod/opt/modulefiles/base/libraries/zlib/1.2.13--gcc--11.3.0:/leonardo/prod/opt/modulefiles/base/libraries/openmpi/4.1.4--gcc--11.3.0-cuda-11.8:/leonardo/prod/opt/modulefiles/deeplrn/libraries/cineca-ai/3.0.0; export _LMFILES_;
LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8:profile/deeplrn:zlib/1.2.13--gcc--11.3.0:openmpi/4.1.4--gcc--11.3.0-cuda-11.8:cineca-ai/3.0.0; export LOADEDMODULES;
CMAKE_PREFIX_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/.:/leonardo/prod/opt/compilers/cuda/11.8/none/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.; export CMAKE_PREFIX_PATH;
OPENMPI_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include; export OPENMPI_INCLUDE;
__MODULES_LMTAG=gmp/6.2.1\&auto-loaded:mpfr/4.1.0\&auto-loaded:mpc/1.2.1\&auto-loaded:zlib/1.2.13--gcc--11.3.0\&auto-loaded:openmpi/4.1.4--gcc--11.3.0-cuda-11.8\&auto-loaded; export __MODULES_LMTAG;
PKG_CONFIG_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib/pkgconfig:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig; export PKG_CONFIG_PATH;
MPICC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpicc; export MPICC;
ZLIB_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include; export ZLIB_INCLUDE;
OMPI_MCA_coll_hcoll_enable=0; export OMPI_MCA_coll_hcoll_enable;
__MODULES_LMPREREQ=mpfr/4.1.0\&gmp/6.2.1:mpc/1.2.1\&gmp/6.2.1\&mpfr/4.1.0:gcc/11.3.0\&gmp/6.2.1\&mpc/1.2.1\&mpfr/4.1.0:openmpi/4.1.4--gcc--11.3.0-cuda-11.8\&zlib/1.2.13--gcc--11.3.0:cineca-ai/3.0.0\&cuda/11.8\&openmpi/4.1.4--gcc--11.3.0-cuda-11.8; export __MODULES_LMPREREQ;
CPLUS_INCLUDE_PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export CPLUS_INCLUDE_PATH;
CINECA_AI_INCLUDE=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/include; export CINECA_AI_INCLUDE;
OPENMPI_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn; export OPENMPI_HOME;
MPICXX=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpic++; export MPICXX;
OPENMPI_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include; export OPENMPI_INC;
__MODULES_LMALTNAME=profile/base\&profile/default\&profile:gmp/6.2.1\&as\|gmp/default\&as\|gmp/latest:mpfr/4.1.0\&as\|mpfr/default\&as\|mpfr/latest:mpc/1.2.1\&as\|mpc/default\&as\|mpc/latest:gcc/11.3.0\&as\|gcc/default\&as\|gcc/latest:cuda/11.8\&as\|cuda/default\&as\|cuda/latest:zlib/1.2.13--gcc--11.3.0\&as\|zlib/default\&as\|zlib/latest:cineca-ai/3.0.0\&as\|cineca-ai/default\&as\|cineca-ai/latest; export __MODULES_LMALTNAME;
__MODULES_LMCONFLICT=gmp/6.2.1\&gmp:mpfr/4.1.0\&mpfr:mpc/1.2.1\&mpc:gcc/11.3.0\&gcc:cuda/11.8\&cuda:zlib/1.2.13--gcc--11.3.0\&zlib:openmpi/4.1.4--gcc--11.3.0-cuda-11.8\&openmpi:cineca-ai/3.0.0\&cineca-ai; export __MODULES_LMCONFLICT;
ZLIB_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include; export ZLIB_INC;
C_INCLUDE_PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include; export C_INCLUDE_PATH;
CINECA_AI_HOME=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none; export CINECA_AI_HOME;
CINECA_AI_INC=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/include; export CINECA_AI_INC;
MPIF90=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpif90; export MPIF90;
PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/bin:/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin:/leonardo/prod/opt/compilers/cuda/11.8/none/samples/bin/x86_64/linux/release/:/leonardo/prod/opt/compilers/cuda/11.8/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin; export PATH;
OPENMPI_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib; export OPENMPI_LIB;
ZLIB_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib; export ZLIB_LIB;
test 0;'
++ LD_LIBRARY_PATH=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/lib:/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/lib64:/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib:/leonardo/prod/opt/compilers/cuda/11.8/none/compat:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LD_LIBRARY_PATH
++ CPATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/python-3.10.8-eauysn2mronkqqffs7r6bvftsdpsfm4b/include/python3.10:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPATH
++ LIBRARY_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib64:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib
++ export LIBRARY_PATH
++ MANPATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/share/man:/leonardo/prod/opt/compilers/cuda/11.8/none/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/share/man:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/share/man
++ export MANPATH
++ ZLIB_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk
++ export ZLIB_HOME
++ CINECA_AI_LIB=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/lib
++ export CINECA_AI_LIB
++ MPIF77=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpif77
++ export MPIF77
++ _LMFILES_=/leonardo/prod/opt/modulefiles/profiles/profile/base:/leonardo/prod/opt/modulefiles/base/dependencies/gmp/6.2.1:/leonardo/prod/opt/modulefiles/base/dependencies/mpfr/4.1.0:/leonardo/prod/opt/modulefiles/base/dependencies/mpc/1.2.1:/leonardo/prod/opt/modulefiles/base/compilers/gcc/11.3.0:/leonardo/prod/opt/modulefiles/base/compilers/cuda/11.8:/leonardo/prod/opt/modulefiles/profiles/profile/deeplrn:/leonardo/prod/opt/modulefiles/base/libraries/zlib/1.2.13--gcc--11.3.0:/leonardo/prod/opt/modulefiles/base/libraries/openmpi/4.1.4--gcc--11.3.0-cuda-11.8:/leonardo/prod/opt/modulefiles/deeplrn/libraries/cineca-ai/3.0.0
++ export _LMFILES_
++ LOADEDMODULES=profile/base:gmp/6.2.1:mpfr/4.1.0:mpc/1.2.1:gcc/11.3.0:cuda/11.8:profile/deeplrn:zlib/1.2.13--gcc--11.3.0:openmpi/4.1.4--gcc--11.3.0-cuda-11.8:cineca-ai/3.0.0
++ export LOADEDMODULES
++ CMAKE_PREFIX_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/.:/leonardo/prod/opt/compilers/cuda/11.8/none/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/.:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/.
++ export CMAKE_PREFIX_PATH
++ OPENMPI_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include
++ export OPENMPI_INCLUDE
++ __MODULES_LMTAG='gmp/6.2.1&auto-loaded:mpfr/4.1.0&auto-loaded:mpc/1.2.1&auto-loaded:zlib/1.2.13--gcc--11.3.0&auto-loaded:openmpi/4.1.4--gcc--11.3.0-cuda-11.8&auto-loaded'
++ export __MODULES_LMTAG
++ PKG_CONFIG_PATH=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib/pkgconfig:/leonardo/prod/opt/compilers/cuda/11.8/none/lib64/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/lib/pkgconfig:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/lib/pkgconfig
++ export PKG_CONFIG_PATH
++ MPICC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpicc
++ export MPICC
++ ZLIB_INCLUDE=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include
++ export ZLIB_INCLUDE
++ OMPI_MCA_coll_hcoll_enable=0
++ export OMPI_MCA_coll_hcoll_enable
++ __MODULES_LMPREREQ='mpfr/4.1.0&gmp/6.2.1:mpc/1.2.1&gmp/6.2.1&mpfr/4.1.0:gcc/11.3.0&gmp/6.2.1&mpc/1.2.1&mpfr/4.1.0:openmpi/4.1.4--gcc--11.3.0-cuda-11.8&zlib/1.2.13--gcc--11.3.0:cineca-ai/3.0.0&cuda/11.8&openmpi/4.1.4--gcc--11.3.0-cuda-11.8'
++ export __MODULES_LMPREREQ
++ CPLUS_INCLUDE_PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export CPLUS_INCLUDE_PATH
++ CINECA_AI_INCLUDE=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/include
++ export CINECA_AI_INCLUDE
++ OPENMPI_HOME=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn
++ export OPENMPI_HOME
++ MPICXX=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpic++
++ export MPICXX
++ OPENMPI_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include
++ export OPENMPI_INC
++ __MODULES_LMALTNAME='profile/base&profile/default&profile:gmp/6.2.1&as|gmp/default&as|gmp/latest:mpfr/4.1.0&as|mpfr/default&as|mpfr/latest:mpc/1.2.1&as|mpc/default&as|mpc/latest:gcc/11.3.0&as|gcc/default&as|gcc/latest:cuda/11.8&as|cuda/default&as|cuda/latest:zlib/1.2.13--gcc--11.3.0&as|zlib/default&as|zlib/latest:cineca-ai/3.0.0&as|cineca-ai/default&as|cineca-ai/latest'
++ export __MODULES_LMALTNAME
++ __MODULES_LMCONFLICT='gmp/6.2.1&gmp:mpfr/4.1.0&mpfr:mpc/1.2.1&mpc:gcc/11.3.0&gcc:cuda/11.8&cuda:zlib/1.2.13--gcc--11.3.0&zlib:openmpi/4.1.4--gcc--11.3.0-cuda-11.8&openmpi:cineca-ai/3.0.0&cineca-ai'
++ export __MODULES_LMCONFLICT
++ ZLIB_INC=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include
++ export ZLIB_INC
++ C_INCLUDE_PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/include:/leonardo/prod/opt/compilers/cuda/11.8/none/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpc-1.2.1-ndktnvrbytlmmfwre4fs5qbyzzso7fxb/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/mpfr-4.1.0-w4ofd2ll4ftu53yawc4d3sssrmeo2huc/include:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gmp-6.2.1-i7u7hnaqpscmi2x4ffsz6so6fftszm22/include
++ export C_INCLUDE_PATH
++ CINECA_AI_HOME=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none
++ export CINECA_AI_HOME
++ CINECA_AI_INC=/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/include
++ export CINECA_AI_INC
++ MPIF90=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin/mpif90
++ export MPIF90
++ PATH=/leonardo/prod/spack/03/ccsdeploy/spack_deploy/envs/cineca-ai-3/view/bin:/leonardo/prod/opt/libraries/cineca-ai/3.0.0/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/bin:/leonardo/prod/opt/compilers/cuda/11.8/none/samples/bin/x86_64/linux/release/:/leonardo/prod/opt/compilers/cuda/11.8/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/gcc-11.3.0-tm6phj7wkcw7cuy6gjixemkvh5x2mhza/bin:/cineca/bin:/leonardo/home/userexternal/gpuccett/.vscode-server/bin/abd2f3db4bdb28f9e95536dfa84d8479f1eb312d/bin/remote-cli:/cineca/bin:/leonardo/home/userexternal/gpuccett/.local/bin:/leonardo/home/userexternal/gpuccett/bin:/cineca/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ OPENMPI_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/openmpi-4.1.4-si334jjzldoxyl3jbbb3cf6legzshlqn/lib
++ export OPENMPI_LIB
++ ZLIB_LIB=/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-11.3.0/zlib-1.2.13-noknejuy3uxqyxfetsmtnvb6zna3zaxk/lib
++ export ZLIB_LIB
++ test 0
+ _mlstatus=0
+ return 0
+ source /leonardo_work/IscrC_GELATINO/gpuccett/llm-foundry_gpucce/venv/bin/activate
/var/spool/slurmd/job1607152/slurm_script: line 19: /leonardo_work/IscrC_GELATINO/gpuccett/llm-foundry_gpucce/venv/bin/activate: No such file or directory
+ srun /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/train/fine_tuning_commands/test_salloc_llama-70b-finetune_multinode_8nodes_4gpus.sbatch
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Unloading profile/base
  ERROR: Module evaluation aborted
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
Loading cineca-ai/3.0.0
  Loading requirement: zlib/1.2.13--gcc--11.3.0
    openmpi/4.1.4--gcc--11.3.0-cuda-11.8
4: LOCAL_WORLD_SIZE=
7: LOCAL_WORLD_SIZE=
4: LOCAL_WORLD_SIZE=4
4: NPROC=4
4: WORLD SIZE=32
0: LOCAL_WORLD_SIZE=
0: LOCAL_WORLD_SIZE=4
0: NPROC=4
0: WORLD SIZE=32
5: LOCAL_WORLD_SIZE=
2: LOCAL_WORLD_SIZE=
7: LOCAL_WORLD_SIZE=4
7: NPROC=4
6: LOCAL_WORLD_SIZE=
6: LOCAL_WORLD_SIZE=4
6: NPROC=4
6: WORLD SIZE=32
7: WORLD SIZE=32
2: LOCAL_WORLD_SIZE=4
1: LOCAL_WORLD_SIZE=
1: LOCAL_WORLD_SIZE=4
1: NPROC=4
1: WORLD SIZE=32
2: NPROC=4
3: LOCAL_WORLD_SIZE=
3: LOCAL_WORLD_SIZE=4
3: NPROC=4
3: WORLD SIZE=32
2: WORLD SIZE=32
5: LOCAL_WORLD_SIZE=4
5: NPROC=4
5: WORLD SIZE=32
0: MASTER_ADDR=lrdn0074
0: MASTER PORT=54321
0: PYTHONUNBUFFERED=1
0: BASE_RANK=0, NODEID=0
0: LOCAL_RANK=0
3: MASTER_ADDR=lrdn0074
3: MASTER PORT=54321
3: PYTHONUNBUFFERED=1
3: BASE_RANK=12, NODEID=3
3: LOCAL_RANK=0
7: MASTER_ADDR=lrdn0074
7: MASTER PORT=54321
2: MASTER_ADDR=lrdn0074
7: PYTHONUNBUFFERED=1
4: MASTER_ADDR=lrdn0074
2: MASTER PORT=54321
7: BASE_RANK=28, NODEID=7
2: PYTHONUNBUFFERED=1
7: LOCAL_RANK=0
4: MASTER PORT=54321
2: BASE_RANK=8, NODEID=2
4: PYTHONUNBUFFERED=1
2: LOCAL_RANK=0
4: BASE_RANK=16, NODEID=4
4: LOCAL_RANK=0
1: MASTER_ADDR=lrdn0074
1: MASTER PORT=54321
1: PYTHONUNBUFFERED=1
1: BASE_RANK=4, NODEID=1
1: LOCAL_RANK=0
5: MASTER_ADDR=lrdn0074
5: MASTER PORT=54321
5: PYTHONUNBUFFERED=1
5: BASE_RANK=20, NODEID=5
5: LOCAL_RANK=0
6: MASTER_ADDR=lrdn0074
6: MASTER PORT=54321
6: PYTHONUNBUFFERED=1
6: BASE_RANK=24, NODEID=6
6: LOCAL_RANK=0
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Using pad_token, but it is not set yet.
Building train loader...
Building train loader...
Building train loader...
Using pad_token, but it is not set yet.
Building train loader...
Using pad_token, but it is not set yet.
Building train loader...
Building train loader...
Building train loader...
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Building eval loader...
Initializing model...
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:23<05:23, 23.09s/it]Loading checkpoint shards:  13%|        | 2/15 [00:47<05:06, 23.61s/it]Loading checkpoint shards:  20%|        | 3/15 [01:06<04:22, 21.84s/it]Loading checkpoint shards:  27%|       | 4/15 [01:28<04:00, 21.88s/it]Loading checkpoint shards:  33%|      | 5/15 [01:54<03:52, 23.21s/it]Loading checkpoint shards:  40%|      | 6/15 [02:11<03:11, 21.25s/it]Loading checkpoint shards:  47%|     | 7/15 [02:30<02:42, 20.34s/it]Loading checkpoint shards:  53%|    | 8/15 [02:51<02:23, 20.50s/it]Loading checkpoint shards:  60%|    | 9/15 [03:12<02:05, 20.89s/it]Loading checkpoint shards:  67%|   | 10/15 [03:32<01:43, 20.66s/it]Loading checkpoint shards:  73%|  | 11/15 [03:56<01:25, 21.46s/it]Loading checkpoint shards:  80%|Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:16<03:53, 16.67s/it]Loading checkpoint shards:  13%|        | 2/15 [00:33<03:38, 16.81s/it]Loading checkpoint shards:  20%|        | 3/15 [00:53<03:37, 18.13s/it]Loading checkpoint shards:  27%|       | 4/15 [01:15<03:35, 19.62s/it]Loading checkpoint shards:  33%|      | 5/15 [01:40<03:37, 21.78s/it]Loading checkpoint shards:  40%|      | 6/15 [01:58<03:02, 20.32s/it]Loading checkpoint shards:  47%|     | 7/15 [02:16<02:37, 19.71s/it]Loading checkpoint shards:  53%|    | 8/15 [02:37<02:20, 20.07s/it]Loading checkpoint shards:  60%|    | 9/15 [02:59<02:03, 20.59s/it]Loading checkpoint shards:  67%|   | 10/15 [03:19<01:42, 20.45s/it]Loading checkpoint shards:  73%|  | 11/15 [03:42<01:25, 21.32s/it]Loading checkpoint shards:  80%|  | 12/15 [04:06<01:06, 22.01s/it]ERROR:composer.cli.launcher:Rank 18 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
Loading checkpoint shards:  80%|  | 12/15 [04:20<01:05, 21.67s/it]
Global rank 16 (PID 157732) exited with code 143
Global rank 17 (PID 157733) exited with code 1
----------Begin global rank 17 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 17 STDOUT----------
----------Begin global rank 17 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [17] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x1499a6bd04d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x1499a6b9a434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x1499d21398c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x1499d213a572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x1499d213a5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1499d20f9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1499d20f9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1499d20f9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x1499a7b5fc4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x1499a7b63901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x1499a7b6aa2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x1499a7b6be31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x1499a7b6eaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x1499a7b7da41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x1499d20ee2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x1499d20f202a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x1499d2100e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x1499e677efee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x1499e5fca285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x149a1fc38cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 17 STDERR----------
Global rank 18 (PID 157734) exited with code 1
----------Begin global rank 18 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 18 STDOUT----------
----------Begin global rank 18 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [18] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14d9958514d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14d99581b434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14d9c0dba8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14d9c0dbb572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14d9c0dbb5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d9c0d7aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d9c0d7aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d9c0d7aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14d9967e0c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14d9967e4901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14d9967eba2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14d9967ece31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14d9967efaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14d9967fea41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14d9c0d6f2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14d9c0d7302a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14d9c0d81e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14d9d53fffee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14d9d4c4b285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14da0e8b9cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 18 STDERR----------
Global rank 19 (PID 157735) exited with code 1
----------Begin global rank 19 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 19 STDOUT----------
----------Begin global rank 19 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
ERROR:composer.cli.launcher:Global rank 16 (PID 157732) exited with code 143
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [19] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14afc39824d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14afc394c434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14afeeeeb8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14afeeeec572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14afeeeec5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14afeeeabac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14afeeeabac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14afeeeabac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14afc4911c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14afc4915901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14afc491ca2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14afc491de31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14afc4920aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14afc492fa41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14afeeea02d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14afeeea402a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14afeeeb2e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14b003530fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14b002d7c285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14b03c9eacf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 19 STDERR----------
srun: error: lrdn0109: task 4: Exited with exit code 143
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:37<08:44, 37.50s/it]Loading checkpoint shards:  13%|        | 2/15 [01:02<06:32, 30.23s/it]Loading checkpoint shards:  20%|        | 3/15 [01:24<05:16, 26.39s/it]Loading checkpoint shards:  27%|       | 4/15 [01:46<04:29, 24.52s/it]Loading checkpoint shards:  33%|      | 5/15 [02:12<04:11, 25.17s/it]Loading checkpoint shards:  40%|      | 6/15 [02:30<03:25, 22.87s/it]Loading checkpoint shards:  47%|     | 7/15 [02:49<02:51, 21.44s/it]Loading checkpoint shards:  53%|    | 8/15 [03:11<02:31, 21.61s/it]Loading checkpoint shards:  60%|    | 9/15 [03:32<02:09, 21.53s/it]Loading checkpoint shards:  67%|   | 10/15 [03:52<01:45, 21.08s/it]Loading checkpoint shards:  73%|  | 11/15 [04:16<01:27, 21.86s/it]Loading checkpoint shards:  80%|Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:29<06:52, 29.43s/it]Loading checkpoint shards:  13%|        | 2/15 [00:51<05:25, 25.01s/it]Loading checkpoint shards:  20%|        | 3/15 [01:13<04:42, 23.56s/it]Loading checkpoint shards:  27%|       | 4/15 [01:34<04:10, 22.80s/it]Loading checkpoint shards:  33%|      | 5/15 [02:01<04:00, 24.09s/it]Loading checkpoint shards:  40%|      | 6/15 [02:19<03:19, 22.13s/it]Loading checkpoint shards:  47%|     | 7/15 [02:38<02:47, 20.95s/it]Loading checkpoint shards:  53%|    | 8/15 [03:00<02:28, 21.28s/it]Loading checkpoint shards:  60%|    | 9/15 [03:21<02:07, 21.31s/it]Loading checkpoint shards:  67%|   | 10/15 [03:41<01:44, 20.93s/it]Loading checkpoint shards:  73%|  | 11/15 [04:05<01:27, 21.75s/it]Loading checkpoint shards:  80%|Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:38<09:03, 38.83s/it]Loading checkpoint shards:  13%|        | 2/15 [01:01<06:23, 29.49s/it]Loading checkpoint shards:  20%|        | 3/15 [01:23<05:11, 25.99s/it]Loading checkpoint shards:  27%|       | 4/15 [01:44<04:25, 24.17s/it]Loading checkpoint shards:  33%|      | 5/15 [02:11<04:10, 25.04s/it]Loading checkpoint shards:  40%|      | 6/15 [02:29<03:24, 22.77s/it]Loading checkpoint shards:  47%|     | 7/15 [02:48<02:51, 21.39s/it]Loading checkpoint shards:  53%|    | 8/15 [03:10<02:31, 21.58s/it]Loading checkpoint shards:  60%|    | 9/15 [03:31<02:09, 21.50s/it]Loading checkpoint shards:  67%|   | 10/15 [03:51<01:45, 21.07s/it]Loading checkpoint shards:  73%|  | 11/15 [04:15<01:27, 21.84s/it]Loading checkpoint shards:  80%|Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:45<10:36, 45.49s/it]Loading checkpoint shards:  13%|        | 2/15 [01:06<06:44, 31.14s/it]Loading checkpoint shards:  20%|        | 3/15 [01:28<05:22, 26.89s/it]Loading checkpoint shards:  27%|       | 4/15 [01:49<04:31, 24.69s/it]Loading checkpoint shards:  33%|      | 5/15 [02:16<04:13, 25.40s/it]Loading checkpoint shards:  40%|      | 6/15 [02:34<03:27, 23.02s/it]Loading checkpoint shards:  47%|     | 7/15 [02:53<02:52, 21.55s/it]Loading checkpoint shards:  53%|    | 8/15 [03:15<02:31, 21.69s/it]Loading checkpoint shards:  60%|    | 9/15 [03:36<02:09, 21.58s/it]Loading checkpoint shards:  67%|   | 10/15 [03:56<01:45, 21.12s/it]Loading checkpoint shards:  73%|  | 11/15 [04:20<01:27, 21.87s/it]Loading checkpoint shards:  80%|Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:42<10:01, 42.95s/it]Loading checkpoint shards:  13%|        | 2/15 [01:00<06:05, 28.09s/it]Loading checkpoint shards:  20%|        | 3/15 [01:22<05:02, 25.23s/it]Loading checkpoint shards:  27%|       | 4/15 [01:43<04:20, 23.69s/it]Loading checkpoint shards:  33%|      | 5/15 [02:10<04:07, 24.75s/it]Loading checkpoint shards:  40%|      | 6/15 [02:28<03:23, 22.59s/it]Loading checkpoint shards:  47%|     | 7/15 [02:47<02:50, 21.26s/it]Loading checkpoint shards:  53%|    | 8/15 [03:09<02:30, 21.49s/it]Loading checkpoint shards:  60%|    | 9/15 [03:30<02:08, 21.44s/it]Loading checkpoint shards:  67%|   | 10/15 [03:50<01:45, 21.02s/it]Loading checkpoint shards:  73%|  | 11/15 [04:14<01:27, 21.81s/it]Loading checkpoint shards:  80%|  | 12/15 [04:39<01:06, 22.29s/it]ERROR:composer.cli.launcher:Rank 6 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
  | 12/15 [04:28<01:06, 22.22s/it]ERROR:composer.cli.launcher:Rank 25 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
  | 12/15 [04:19<01:06, 22.11s/it]Loading checkpoint shards:  87%| | 13/15 [04:37<00:41, 20.86s/it]ERROR:composer.cli.launcher:Rank 22 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|         | 1/15 [00:52<12:11, 52.22s/it]Loading checkpoint shards:  13%|        | 2/15 [01:16<07:46, 35.89s/it]Loading checkpoint shards:  20%|        | 3/15 [01:35<05:39, 28.29s/it]Loading checkpoint shards:  27%|       | 4/15 [01:54<04:29, 24.52s/it]Loading checkpoint shards:  33%|      | 5/15 [02:20<04:10, 25.03s/it]Loading checkpoint shards:  40%|      | 6/15 [02:38<03:23, 22.64s/it]Loading checkpoint shards:  47%|     | 7/15 [02:59<02:55, 21.99s/it]Loading checkpoint shards:  53%|    | 8/15 [03:18<02:28, 21.21s/it]Loading checkpoint shards:  60%|    | 9/15 [03:40<02:08, 21.41s/it]Loading checkpoint shards:  67%|   | 10/15 [04:00<01:44, 20.82s/it]Loading checkpoint shards:  73%|  | 11/15 [04:22<01:24, 21.19s/it]ERROR:composer.cli.launcher:Rank 2 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
  | 12/15 [04:43<01:06, 22.31s/it]ERROR:composer.cli.launcher:Rank 29 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
Loading checkpoint shards:  80%|  | 12/15 [04:44<01:11, 23.67s/it]
Loading checkpoint shards:  80%|  | 12/15 [04:40<01:10, 23.35s/it]
Loading checkpoint shards:  80%|  | 12/15 [04:28<01:07, 22.41s/it]
Loading checkpoint shards:  87%| | 13/15 [04:51<00:44, 22.46s/it]
Loading checkpoint shards:  73%|  | 11/15 [04:26<01:36, 24.19s/it]
  | 12/15 [04:38<01:06, 22.29s/it]ERROR:composer.cli.launcher:Rank 13 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
  | 12/15 [04:37<01:06, 22.28s/it]ERROR:composer.cli.launcher:Rank 10 crashed with exit code 1.
Waiting up to 30 seconds for all training processes to terminate. Press Ctrl-C to exit immediately.
Loading checkpoint shards:  80%|  | 12/15 [04:42<01:10, 23.52s/it]
Loading checkpoint shards:  80%|  | 12/15 [04:41<01:10, 23.43s/it]
Global rank 24 (PID 144799) exited with code 143
Global rank 25 (PID 144800) exited with code 1
----------Begin global rank 25 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 25 STDOUT----------
----------Begin global rank 25 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [25] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14d11270b4d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14d1126d5434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14d13dc748c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14d13dc75572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14d13dc755f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d13dc34ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d13dc34ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14d13dc34ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14d11369ac4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14d11369e901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14d1136a5a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14d1136a6e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14d1136a9aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14d1136b8a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14d13dc292d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14d13dc2d02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14d13dc3be90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14d1522b9fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14d151b05285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14d18b773cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 25 STDERR----------
Global rank 26 (PID 144801) exited with code 1
----------Begin global rank 26 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 26 STDOUT----------
----------Begin global rank 26 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [26] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x147e865614d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x147e8652b434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x147eb1aca8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x147eb1acb572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x147eb1acb5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147eb1a8aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147eb1a8aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147eb1a8aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x147e874f0c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x147e874f4901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x147e874fba2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x147e874fce31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x147e874ffaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x147e8750ea41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x147eb1a7f2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x147eb1a8302a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x147eb1a91e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x147ec610ffee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x147ec595b285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x147eff5c9cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 26 STDERR----------
Global rank 27 (PID 144802) exited with code 1
----------Begin global rank 27 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 27 STDOUT----------
----------Begin global rank 27 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [27] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14ac3eeac4d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14ac3ee76434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14ac6a4158c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14ac6a416572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14ac6a4165f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ac6a3d5ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ac6a3d5ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ac6a3d5ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14ac3fe3bc4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14ac3fe3f901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14ac3fe46a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14ac3fe47e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14ac3fe4aaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14ac3fe59a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14ac6a3ca2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14ac6a3ce02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14ac6a3dce90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14ac7ea5afee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14ac7e2a6285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14acb7f14cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 27 STDERR----------
ERROR:composer.cli.launcher:Global rank 24 (PID 144799) exited with code 143
Global rank 28 (PID 182789) exited with code 143
Global rank 29 (PID 182790) exited with code 1
----------Begin global rank 29 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 29 STDOUT----------
----------Begin global rank 29 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [29] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14ad845e14d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14ad845ab434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14adafb4a8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14adafb4b572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14adafb4b5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14adafb0aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14adafb0aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14adafb0aac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14ad85570c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14ad85574901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14ad8557ba2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14ad8557ce31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14ad8557faed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14ad8558ea41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14adafaff2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14adafb0302a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14adafb11e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14adc418ffee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14adc39db285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14adfd649cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 29 STDERR----------
Global rank 30 (PID 182791) exited with code 1
----------Begin global rank 30 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 30 STDOUT----------
----------Begin global rank 30 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [30] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14e9945904d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14e99455a434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14e9bfaf98c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14e9bfafa572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14e9bfafa5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14e9bfab9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14e9bfab9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14e9bfab9ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14e99551fc4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14e995523901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14e99552aa2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14e99552be31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14e99552eaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14e99553da41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14e9bfaae2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14e9bfab202a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14e9bfac0e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14e9d413efee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14e9d398a285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14ea0d5f8cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 30 STDERR----------
Global rank 31 (PID 182792) exited with code 1
----------Begin global rank 31 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 31 STDOUT----------
----------Begin global rank 31 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [31] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14df567c24d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14df5678c434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14df81d2b8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14df81d2c572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14df81d2c5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14df81cebac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14df81cebac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14df81cebac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14df57751c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14df57755901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14df5775ca2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14df5775de31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14df57760aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14df5776fa41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14df81ce02d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14df81ce402a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14df81cf2e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14df96370fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14df95bbc285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14dfcf82acf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 31 STDERR----------
ERROR:composer.cli.launcher:Global rank 28 (PID 182789) exited with code 143
Global rank 4 (PID 186030) exited with code 143
Global rank 5 (PID 186031) exited with code 1
----------Begin global rank 5 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 5 STDOUT----------
----------Begin global rank 5 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [5] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14dd6dd124d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14dd6dcdc434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14dd9927b8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14dd9927c572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14dd9927c5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14dd9923bac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14dd9923bac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14dd9923bac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14dd6eca1c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14dd6eca5901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14dd6ecaca2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14dd6ecade31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14dd6ecb0aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14dd6ecbfa41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14dd992302d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14dd9923402a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14dd99242e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14ddad8c0fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14ddad10c285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14dde6d7acf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 5 STDERR----------
Global rank 6 (PID 186032) exited with code 1
----------Begin global rank 6 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 6 STDOUT----------
----------Begin global rank 6 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [6] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14c6c3f5f4d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14c6c3f29434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14c6ef4c88c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14c6ef4c9572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14c6ef4c95f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c6ef488ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c6ef488ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c6ef488ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14c6c4eeec4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14c6c4ef2901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14c6c4ef9a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14c6c4efae31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14c6c4efdaed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14c6c4f0ca41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14c6ef47d2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14c6ef48102a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14c6ef48fe90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14c703b0dfee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14c703359285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14c73cfc7cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 6 STDERR----------
Global rank 7 (PID 186033) exited with code 1
----------Begin global rank 7 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 7 STDOUT----------
----------Begin global rank 7 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [7] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x147ccfab94d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x147ccfa83434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x147cfb0228c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x147cfb023572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x147cfb0235f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147cfafe2ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147cfafe2ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147cfafe2ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x147cd0a48c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x147cd0a4c901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x147cd0a53a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x147cd0a54e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x147cd0a57aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x147cd0a66a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x147cfafd72d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x147cfafdb02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x147cfafe9e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x147d0f667fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x147d0eeb3285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x147d48b21cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 7 STDERR----------
ERROR:composer.cli.launcher:Global rank 4 (PID 186030) exited with code 143
Global rank 0 (PID 187128) exited with code 143
Global rank 1 (PID 187129) exited with code 1
----------Begin global rank 1 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 1 STDOUT----------
----------Begin global rank 1 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [1] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x147c2746a4d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x147c27434434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x147c529d38c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x147c529d4572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x147c529d45f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147c52993ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147c52993ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x147c52993ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x147c283f9c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x147c283fd901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x147c28404a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x147c28405e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x147c28408aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x147c28417a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x147c529882d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x147c5298c02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x147c5299ae90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x147c67018fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x147c66864285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x147ca04d2cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 1 STDERR----------
Global rank 2 (PID 187130) exited with code 1
----------Begin global rank 2 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 2 STDOUT----------
----------Begin global rank 2 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [2] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x15017ef824d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x15017ef4c434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x1501aa4eb8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x1501aa4ec572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x1501aa4ec5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1501aa4abac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1501aa4abac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1501aa4abac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x15017ff11c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x15017ff15901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x15017ff1ca2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x15017ff1de31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x15017ff20aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x15017ff2fa41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x1501aa4a02d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x1501aa4a402a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x1501aa4b2e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x1501beb30fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x1501be37c285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x1501f7feacf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 2 STDERR----------
Global rank 3 (PID 187131) exited with code 1
----------Begin global rank 3 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 3 STDOUT----------
----------Begin global rank 3 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [3] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14c8266d94d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14c8266a3434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14c851c428c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14c851c43572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14c851c435f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c851c02ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c851c02ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14c851c02ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14c827668c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14c82766c901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14c827673a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14c827674e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14c827677aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14c827686a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14c851bf72d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14c851bfb02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14c851c09e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14c866287fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14c865ad3285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14c89f741cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 3 STDERR----------
ERROR:composer.cli.launcher:Global rank 0 (PID 187128) exited with code 143
srun: error: lrdn0133: task 6: Exited with exit code 143
Global rank 20 (PID 143024) exited with code 143
Global rank 21 (PID 143025) exited with code 1
----------Begin global rank 21 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 21 STDOUT----------
----------Begin global rank 21 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [21] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14fa97e764d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14fa97e40434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14fac33df8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14fac33e0572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14fac33e05f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14fac339fac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14fac339fac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14fac339fac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14fa98e05c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14fa98e09901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14fa98e10a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14fa98e11e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14fa98e14aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14fa98e23a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14fac33942d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14fac339802a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14fac33a6e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14fad7a24fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14fad7270285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14fb10edecf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 21 STDERR----------
Global rank 22 (PID 143026) exited with code 1
----------Begin global rank 22 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 22 STDOUT----------
----------Begin global rank 22 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [22] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14b47de544d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14b47de1e434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14b4a93bd8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14b4a93be572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14b4a93be5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14b4a937dac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14b4a937dac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14b4a937dac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14b47ede3c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14b47ede7901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14b47edeea2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14b47edefe31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14b47edf2aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14b47ee01a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14b4a93722d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14b4a937602a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14b4a9384e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14b4bda02fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14b4bd24e285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14b4f6ebccf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 22 STDERR----------
Global rank 23 (PID 143027) exited with code 1
----------Begin global rank 23 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 23 STDOUT----------
----------Begin global rank 23 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [23] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x153f8c1084d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x153f8c0d2434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x153fb76718c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x153fb7672572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x153fb76725f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x153fb7631ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x153fb7631ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x153fb7631ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x153f8d097c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x153f8d09b901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x153f8d0a2a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x153f8d0a3e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x153f8d0a6aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x153f8d0b5a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x153fb76262d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x153fb762a02a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x153fb7638e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x153fcbcb6fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x153fcb502285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x154005170cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 23 STDERR----------
ERROR:composer.cli.launcher:Global rank 20 (PID 143024) exited with code 143
srun: error: lrdn0146: task 7: Exited with exit code 143
srun: error: lrdn0080: task 1: Exited with exit code 143
srun: error: lrdn0074: task 0: Exited with exit code 143
srun: error: lrdn0116: task 5: Exited with exit code 143
Global rank 8 (PID 151048) exited with code 143
Global rank 9 (PID 151049) exited with code 1
----------Begin global rank 9 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 9 STDOUT----------
----------Begin global rank 9 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [9] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14ecf40d34d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14ecf409d434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14ed1f63c8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14ed1f63d572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14ed1f63d5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ed1f5fcac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ed1f5fcac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14ed1f5fcac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14ecf5062c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14ecf5066901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14ecf506da2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14ecf506ee31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14ecf5071aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14ecf5080a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14ed1f5f12d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14ed1f5f502a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14ed1f603e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14ed33c81fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14ed334cd285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14ed6d13bcf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 9 STDERR----------
Global rank 10 (PID 151050) exited with code 1
----------Begin global rank 10 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 10 STDOUT----------
----------Begin global rank 10 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [10] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14efb67974d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14efb6761434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14efe1d008c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14efe1d01572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14efe1d015f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14efe1cc0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14efe1cc0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14efe1cc0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14efb7726c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14efb772a901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14efb7731a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14efb7732e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14efb7735aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14efb7744a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14efe1cb52d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14efe1cb902a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14efe1cc7e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14eff6345fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14eff5b91285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14f02f7ffcf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 10 STDERR----------
Global rank 11 (PID 151051) exited with code 1
----------Begin global rank 11 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 11 STDOUT----------
----------Begin global rank 11 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [11] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x15219c5924d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x15219c55c434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x1521c7afb8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x1521c7afc572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x1521c7afc5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1521c7abbac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1521c7abbac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1521c7abbac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x15219d521c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x15219d525901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x15219d52ca2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x15219d52de31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x15219d530aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x15219d53fa41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x1521c7ab02d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x1521c7ab402a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x1521c7ac2e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x1521dc140fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x1521db98c285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x1522155facf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 11 STDERR----------
ERROR:composer.cli.launcher:Global rank 8 (PID 151048) exited with code 143
Global rank 12 (PID 151300) exited with code 143
Global rank 13 (PID 151301) exited with code 1
----------Begin global rank 13 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 13 STDOUT----------
----------Begin global rank 13 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [13] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x1471ab3ff4d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x1471ab3c9434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x1471d69688c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x1471d6969572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x1471d69695f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1471d6928ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1471d6928ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x1471d6928ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x1471ac38ec4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x1471ac392901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x1471ac399a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x1471ac39ae31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x1471ac39daed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x1471ac3aca41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x1471d691d2d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x1471d692102a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x1471d692fe90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x1471eafadfee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x1471ea7f9285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x147224467cf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 13 STDERR----------
Global rank 14 (PID 151302) exited with code 1
----------Begin global rank 14 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 14 STDOUT----------
----------Begin global rank 14 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [14] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x14a55ca774d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x14a55ca41434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x14a587fe08c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x14a587fe1572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x14a587fe15f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14a587fa0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14a587fa0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x14a587fa0ac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x14a55da06c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x14a55da0a901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x14a55da11a2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x14a55da12e31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x14a55da15aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x14a55da24a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x14a587f952d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x14a587f9902a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x14a587fa7e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x14a59c625fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x14a59be71285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x14a5d5adfcf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 14 STDERR----------
Global rank 15 (PID 151303) exited with code 1
----------Begin global rank 15 STDOUT----------
As run_name, save_folder, and save_latest_filename are set,                 changing autoresume default to True...
Building train loader...
Building eval loader...
Initializing model...

----------End global rank 15 STDOUT----------
----------Begin global rank 15 STDERR----------
device_microbatch_size > device_batch_size, will be reduced from 8 -> 4.
Using pad_token, but it is not set yet.
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1006: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
 Traceback (most recent call last) 
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:588 in <module>                                                   
                                                                              
   585    cfg = om.merge(yaml_cfg, cli_cfg)                                  
   586    om.resolve(cfg)                                                    
   587    assert isinstance(cfg, DictConfig)                                 
  588    main(cfg)                                                          
   589                                                                        
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:505 in main                                                       
                                                                              
   502             tokenizer)                                             
   503          print_trainable_parameters(model)  # should not be 100%    
   504       else:  # standard model                                        
  505          model = build_composer_model(model_config, tokenizer)      
   506                                                                      
   507       if model_config.get('master_weights_dtype') in ('bf16', 'bfloa 
   508          model = model.to(dtype=torch.bfloat16)                     
                                                                              
 /leonardo_work/IscrC_GELATINO/gpuccett/Repos/llm-foundry_gpucce/scripts/trai 
 n/train.py:115 in build_composer_model                                       
                                                                              
   112    if model_cfg.name not in COMPOSER_MODEL_REGISTRY:                  
   113       raise ValueError(                                              
   114          f'Not sure how to build model with name={model_cfg.name}') 
  115    return COMPOSER_MODEL_REGISTRY[model_cfg.name](model_cfg, tokenize 
   116                                                                        
   117                                                                        
   118 def build_composer_peft_model(                                         
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/llmfoundry/models/ 
 hf/hf_causal_lm.py:176 in __init__                                           
                                                                              
   173          # so that we don't timeout for large downloads. This syncs 
   174          with dist.local_rank_zero_download_and_wait(signal_file_pa 
   175             # Then, wait to ensure every node has finished downloa 
  176             dist.barrier()                                         
   177                                                                     
   178          if dist.get_global_rank() == 0:                            
   179             os.remove(signal_file_path)                            
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/composer/utils/dist.py:264 in barrier                        
                                                                              
   261    .. seealso:: :func:`torch.distributed.barrier`                     
   262    """                                                                
   263    if dist.is_available() and dist.is_initialized():                  
  264       dist.barrier()                                                 
   265       return                                                         
   266    world_size = get_world_size()                                      
   267    if world_size == 1:                                                
                                                                              
 /leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.1 
 0/site-packages/torch/distributed/distributed_c10d.py:3328 in barrier        
                                                                              
   3325                                                                      
   3326    if group is None:                                                 
   3327       default_pg = _get_default_group()                             
  3328       work = default_pg.barrier(opts=opts)                          
   3329    else:                                                             
   3330       work = group.barrier(opts=opts)                               
   3331                                                                       

RuntimeError: [15] is setting up NCCL communicator and retrieving ncclUniqueId 
from [0] via c10d key-value store by key '0', but store->get('0') got error: 
Socket Timeout
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:604 
(most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 
(0x148a379134d7 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, 
char const*) + 0x68 (0x148a378dd434 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, 
std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0xd8 (0x148a62e7c8c8 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x22 (0x148a62e7d572 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0x59 (0x148a62e7d5f9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x148a62e3cac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x148a62e3cac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x148a62e3cac1 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, 
std::string const&, int) + 0xaf (0x148a388a2c4f in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, 
std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, 
int, bool) + 0x201 (0x148a388a6901 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xecaa2d (0x148a388ada2d in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 
(0x148a388aee31 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, 
std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x39d 
(0x148a388b1aed in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x851 
(0x148a388c0a41 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x538e2d9 (0x148a62e312d9 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x539202a (0x148a62e3502a in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x53a0e90 (0x148a62e43e90 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0xb6bfee (0x148a774c1fee in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
frame #18: <unknown function> + 0x3b7285 (0x148a76d0d285 in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/lib/python3.10/si
te-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #44: __libc_start_main + 0xf3 (0x148ab097bcf3 in /lib64/libc.so.6)
frame #45: _start + 0x2e (0x400f9e in 
/leonardo_scratch/large/userexternal/gpuccett/llm-foundry/venv/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up 
issue.

----------End global rank 15 STDERR----------
ERROR:composer.cli.launcher:Global rank 12 (PID 151300) exited with code 143
srun: error: lrdn0088: task 2: Exited with exit code 143
srun: error: lrdn0098: task 3: Exited with exit code 143
